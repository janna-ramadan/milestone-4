---
title: "milestone4"
author: "Janna Ramadan"
date: "10/16/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(rtweet)
library(tidytext)
library(dplyr)
library(ggplot2)
library(readr)
library(gganimate)
library(shiny)
library(tidymodels)
library(rstanarm)
library(dbplyr)
library(lubridate)
library(janitor)
library(broom.mixed)

```


```{r, hate-crime-data-set-up, error = FALSE}
# Load datasets


fbi2018 <- read_excel("rawdata/fbi2018.xls") %>%
  slice(4: 49) %>%
  select(1, 4) 
  # names(Table 1) <- "Bias Motivation" %>%
  # names(...4) <- "Number of Victims"

fbi2017 <- read_excel("rawdata/fbi2017.xls")%>%
  slice(3: 49) %>%
  select(1, 4)

fbi2016 <- read_excel("rawdata/fbi2016.xls")%>%
  slice(3: 49) %>%
  select(1, 4)

fbi2015 <- read_excel("rawdata/fbi2015.xls") %>%
  slice(3: 49) %>%
  select(1, 4)

fbi2014 <- read_excel("rawdata/fbi2014.xls") %>%
  slice(3: 49) %>%
  select(1, 4)

fbi2013 <- read_excel("rawdata/fbi2013.xls") %>%
  slice(3: 49) %>%
  select(1, 4)

fbi2012 <- read_excel("rawdata/fbi2012.xls") %>%
  slice(3: 49) %>%
  select(1, 4)

```

```{r, hate-crime-making-one-data-set }

# Merge fbi hate crime data sets.

fbi78 <- full_join(fbi2018, fbi2017) %>%
  rename(bias_motivation = "Table 1", count = "...4") %>%
  filter(bias_motivation == "Anti-Islamic (Muslim)" | bias_motivation == "Anti-Arab") 

fbi56 <- full_join(fbi2015, fbi2016) %>%
  rename(bias_motivation = "Table 1", count = "...4") %>%
  filter(bias_motivation == "Anti-Islamic (Muslim)" | bias_motivation == "Anti-Arab") 

fbi34 <- full_join(fbi2013, fbi2014) %>%
  rename(bias_motivation = "Table 1", count = "...4") %>%
  filter(bias_motivation == "Anti-Islamic (Muslim)" | bias_motivation == "Anti-Arab") 

fbi2 <- fbi2012 %>%
  rename(bias_motivation = "Table 1", count = "...4") %>%
  filter(bias_motivation == "Anti-Islamic" | bias_motivation == "Anti-Arab")

  fbi2[1,1] <- "Anti-Islamic (Muslim)"

fbi5_8 <- full_join(fbi56, fbi78)
fbi2_4 <- full_join(fbi2, fbi34)


fbi12_18 <- full_join(fbi2_4, fbi5_8)

fbi12_18$year <- c("2012", "2013", "2014", "2015", "2015", "2016", "2016", "2018", "2018", "2017", "2017")

  fbicompiled <- fbi12_18 %>%
    mutate("count" = as.numeric(count)) %>%
    arrange(desc(count))

    
write_csv(fbicompiled, "fbicompiled.csv")
  
# ^^ Externally downloaded the data so that I could manually add data points from
# 1996 - 2011. Below is complete hate crime data set.

fbi_compiled_complete <- read_csv("milestone4/fbi_compiled_complete.csv",
col_types = list(
  bias_motivation = col_character(),
  count = col_double(),
  year = col_character()
))

fbi_compiled_complete %>%
  filter(bias_motivation == "Anti-Islamic (Muslim)") %>%
  mutate(mean = mean(count))

# ^^ mean Anti-Islamic (Muslim) hate crimes is 163.7826. 

fbi_compiled_complete %>%
  filter(bias_motivation == "Anti-Arab") %>%
  mutate(mean = mean(count))

# ^^ mean Anti-Islamic (Muslim) hate crimes is 84. 

  
```

```{r, hate-crime-graph}

# Hate crime graph

      ggplot(data = fbi_compiled_complete, mapping = aes(x = year, y = count, color = bias_motivation)) +
        geom_point(size = 2) +
        geom_hline(yintercept = 84, col = "olivedrab3", lty = "dashed") +
        geom_hline(yintercept = 163.78, col = "lightskyblue2", lty = "dashed") +
        theme_bw() +
        labs(title = "1996-2018 Count of Hate Crimes Motivated By Anti-Muslim or \nAnti-Arab Sentiment",
             subtitle = "Counts victims of hate crimes within \nthe United States",
             x = "Year",
             y = "Victim Count",
             caption = "Source: FBI Hate Crimes") +
        scale_color_manual(name = "Hate Crime Motivation",
                           labels = c("Anti-Arab \nSentiment", "Anti-Muslim \nSentiment"),
                           values = c("olivedrab3", "lightskyblue2")) +
        theme(axis.text.x = element_text(size = 5, angle = 45),
              text = element_text(family = "Palatino"))

```

```{r, google-trend-news-data}

# Google news trend data download and clean up.

newstrends08_20 <- read_csv("rawdata/googletrends.csv",
  col_types = list(
  Month = col_character(),
  Year = col_double(),
  Month_1 = col_double(),
 `Month (Name)` = col_character(),
 Muslim = col_double(),
   Terrorism = col_double())) %>%  
  clean_names() %>%
  mutate(month = ymd(month, truncated = 1)) 

# Edit data set to set date and reorder based on key word search for each year.

newstrends08_20 <- newstrends08_20 %>%
  pivot_longer(cols = c(muslim, terrorism), 
               names_to = "key_word") %>%
  rename(date = month) %>%
  rename(month = month_1)

# makes csv of cleaned data
write_csv(newstrends08_20, "newstrends0820.csv")

#graph of news search trends
ggplot(data = newstrends08_20, mapping = aes(x = date, 
                                              y = value, 
                                              color = key_word)) +
  geom_line() +
 transition_reveal(date) +
  scale_x_date(date_labels = "%b/%Y", date_breaks = "year") +
  theme(axis.text.x = element_text(size = 5, angle = 90),
              text = element_text(family = "Palatino")) +
  scale_color_manual(values = c("olivedrab3", "brown2"), labels = c("Muslim", "Terorrism"), name = "Key Word Search Term") +
  labs(title = "Level of Search Interest in the Topic 'Muslim' and Search Term 'Terrorist'",
       subtitle = "Values Based on Google News Search Trends Between 2008 and 2020", 
       x = "Date", 
       y = "Relative Interest (with respect to peak search frequency)", 
       caption = "Source: Google News Trends")



```

```{r, newstrend vs hate crime regression}
# count on key words

test3 <- newstrends08_20 %>%
  group_by(year, key_word) %>%
  summarize(mean_value = mean(value)) %>%
  mutate(year = as.character(year)) %>%
  left_join(fbi_compiled_complete, by = "year") %>%
  drop_na() 

fit_1 <- stan_glm(data = test3, 
         count ~ mean_value + key_word - 1,
         refresh = 0) 

# The CI values cross zero and the range is just massive for the impact key
# word searches have on hate crime values, which tells us there's 
# isn't a strong correlation.


#regression table

model_tbl <- tbl_regression(fit_1, intercept = TRUE) %>%
  as_gt() %>%
  tab_header(title = "Predictive Regression of Count of Hate Crimes",
             subtitle = "The Effect of News Searches
             Including Key Words 'Muslim' or 'Terrorism'")

model_tbl

```

```{r}
characteryearnews <- newstrends08_20 %>%
  group_by(year, key_word) %>%
  summarize(mean_value = mean(value)) %>%
  mutate(year = as.character(year)) 


  characteryearnews %>%
    left_join(fbi_compiled_complete, by = "year") %>%
  drop_na() %>%
  stan_glm(data = ., 
         count ~ mean_value + key_word - 1,
         refresh = 0,
         family = gaussian) %>%
  tbl_regression(., intercept = TRUE) %>%
  as_gt() %>%
  tab_header(title = "Predictive Regression of Count of Hate Crimes",
             subtitle = "The Effect of News Searches
             Including Key Words 'Muslim' or 'Terrorism'")

write_csv(characteryearnews, "characteryearnews.csv")
```

