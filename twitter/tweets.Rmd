---
title: "twitter code"
author: "Janna Ramadan"
date: "11/2/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(readxl)
library(rtweet)
library(tidytext)
library(dplyr)
library(ggplot2)
library(readr)
library(gganimate)
library(shiny)
library(textdata)
library(rsample)
library(gtsummary)
library(gt)
library(broom.mixed)
```


```{r}
appname <- "muslimopinion"
  
key <- "nTjL6wXzSH6m0A0NWaYOqJ7qH76Y8q01Jaa1YNujCdjAjk4poQ"

secretkey <- "nTjL6wXzSH6m0A0NWaYOqJ7qH76Y8q01Jaa1YNujCdjAjk4poQ"

muslim_extremist_search_string <- c("muslim extremist", "muslim terrorist", "muslim radical")

# muslim only tweets
muslim_tweets <- search_tweets(type = "recent", 
                                       q = "muslim",
                               n = 1000, 
                               include_rts = FALSE,
                               "lang:en",
                               geocode = lookup_coords("usa"))  %>%
  select("created_at", "text", "hashtags")

  saveRDS(muslim_tweets, file = paste0("muslim_tweets_",Sys.Date(),".RDS"))
  
# Muslim, Arab, South Asian Tweets
  muslim_arab_southasian_tweets <- search_tweets(type = "recent", 
                                       q = "arab OR south asian",
                               n = 1000, 
                               include_rts = FALSE,
                               "lang:en",
                               geocode = lookup_coords("usa"))  %>%
  select("created_at", "text", "hashtags")

  saveRDS(muslim_arab_southasian_tweets, file = paste0("muslim_arab_southasian_tweets_",Sys.Date(),".RDS"))
  

# Islam tweets
islam_tweets <- search_tweets(type = "recent", 
                                       q = "islam",
                               n = 1000, 
                               include_rts = FALSE,
                               "lang:en",
                               geocode = lookup_coords("usa"))  %>%
  select("created_at", "text", "hashtags")

  saveRDS(islam_tweets, file = paste0("islam_tweets_",Sys.Date(),".RDS"))
  
# Anti-democratic tweets
antidem_tweets <- search_tweets(type = "recent", 
                                       q = "anti-democratic",
                               n = 1000, 
                               include_rts = FALSE,
                               "lang:en",
                               geocode = lookup_coords("usa"))  %>%
  select("created_at", "text", "hashtags")

  saveRDS(antidem_tweets, file = paste0("antidem_tweets_",Sys.Date(),".RDS"))

```

```{r}

filelist <- tweets <- list.files(pattern = "*.RDS")

#i in = sets lengths of i; how many files to bound them all

tweeteater <- function(filelist) {
  for(i in 1:length(filelist)){
  subfile = readRDS(filelist[i]) %>%
    mutate(dataset = filelist[i])
    if(i == 1){
      final <- subfile 
    }
    if(i > 1) {
      final <- bind_rows(final, subfile)
    }
  } 
  
  return(final)
  
}

tweetfile <- tweeteater(filelist) %>%
  mutate(date = as.Date(created_at)) %>%
  mutate(filename = str_extract(dataset, ".*(?=_2)"))

# used ? lookahead to get everything before _2 in _2020...

```

```{r, unique word counts}
# for front page - will show the common/unique words that come with each
# twitter search

# Remmoves http elements 
tweetfile$stripped_text <- gsub("http\\S+", 
                                  "",
                                 tweetfile$text)

# converts the tweets into lowercase, removes punctuation, and adds an id for
# each tweet.
# Also removes "stop words" which are words like I, being, have, etc. 
# They are words not useful in sentiment analysis

tweetfile_clean_muslim <- tweetfile %>%
  filter(filename == "muslim_tweets") %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) %>%
  anti_join(stop_words)

tweetfile_clean_arab_sa <- tweetfile %>%
  filter(filename == "muslim_arab_southasian_tweets") %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) %>%
  anti_join(stop_words)

tweetfile_clean_islam <- tweetfile %>%
    filter(filename == "islam_tweets") %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) %>%
  anti_join(stop_words)

tweetfile_clean_antidem <- tweetfile %>%
    filter(filename == "antidem_tweets") %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) %>%
  anti_join(stop_words)

tweetfile_clean <- tweetfile %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) %>%
  anti_join(stop_words)

tweetfile_clean_ethnic <- tweetfile %>%
  filter(filename == c("muslim_tweets", "islam_tweets", "muslim_arab_southasian_tweets")) %>%
  select(stripped_text) %>%
  unnest_tokens(word, stripped_text) %>%
  anti_join(stop_words)

# Can see top tweets with this code head(tweetfile_clean_muslim)
# First look - muslim tweets shows words like hate, condemnation, 
# jihadwatchers, leaving. and taught. The arab & south asian data and islam
# data came up with less conclusive data and words that do not have direct
# ties to islam. antidem data is clearly impacted by the election because 
# repubican and trump were some of the top words.

```

```{r, top 10 words }
# The following graphs have the same format. They look at the top 10 most
# frequent words in the data sets. 

muslimwords <- tweetfile_clean_muslim %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n)) 

  ggplot(data = muslimwords, mapping = aes(x = word, y = n)) +
  geom_col(fill = "firebrick2") +
  xlab(NULL) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 10 Most Frequent Words In Tweets Including \nthe Word
       'Muslim'",
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Count",
       y = "Unique Words")

arabsawords <- tweetfile_clean_arab_sa %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n)) 

  ggplot(data = arabsawords, mapping = aes(x = word, y = n)) +
  geom_col(fill = "firebrick2") +
  xlab(NULL) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 10 Most Frequent Words In Tweets Including \nthe Word 
       'Arab' and 'South Asian",
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Count",
       y = "Unique Words")

# Key words clearly tied to election

islamwords <- tweetfile_clean_islam %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n)) 

  ggplot(data = islamwords, mapping = aes(x = word, y = n)) +
  geom_col(fill = "firebrick2") +
  xlab(NULL) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 10 Most Frequent Words In Tweets Including \nthe Word 
       'Islam'",
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Count",
       y = "Unique Words")

# surprisingly peaceful

antidemwords <- tweetfile_clean_antidem %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n)) 

  ggplot(data = antidemwords, mapping = aes(x = word, y = n)) +
  geom_col(fill = "firebrick2") +
  xlab(NULL) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 10 Most Frequent Words In Tweets Including \nthe Word 'Anti-Democratic'",
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Count",
       y = "Unique Words")

# Again, heavily influenced by the election

totalwords <- tweetfile_clean %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n))


  ggplot(data = totalwords, mapping = aes(x = word, y = n)) +
  geom_col(fill = "slategray2") +
  xlab(NULL) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 10 Most Frequent Words Across Tweets Including \nthe Words 'Muslim, 'Islam', 'Arab', 'South Asian', and 'Anti-Democratic",
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Count",
       y = "Unique Words")
# Anti is the top, but it is weighted by anti-democratic. Clearly impacted by
# the election results and Kamala Harris, the VP-elect

ethnicwords <- tweetfile_clean_ethnic %>%
  count(word, sort = TRUE) %>%
  top_n(20) %>%
  mutate(word = reorder(word, n)) 

  ggplot(data = ethnicwords, mapping = aes(x = word, y = n)) +
  geom_col(fill = "firebrick2") +
  xlab(NULL) +
  coord_flip() +
  theme_minimal() +
  labs(title = "Top 10 Most Frequent Words Across Tweets Including \nthe Words 'Muslim, 'Islam', 'Arab', and 'South Asian'",
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Count",
       y = "Unique Words")

# Shows that anti-democratic did heavily weigh on the word anti-
```

```{r, sentiment analysis muslim}
# Used bing analysis - which counts positive and negative words. Trump is coded
# as positive. 


tweet_muslim_sentiment <- tweetfile_clean_muslim %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n))


  ggplot(data = tweet_muslim_sentiment, mapping = aes(x = word, 
                                                      y = n, 
                                                      fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scale = "free_y")+
  labs(title = "Sentiment In Tweets Including the Word 'Muslim'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = " ",
       y = "Contribution to Sentiment") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) +
  scale_fill_manual(values = c("brown2", "olivedrab3")) 
  
```

```{r, sentiment analysis islam}
# Used bing analysis - which counts positive and negative words. Trump is 
# coded as positive. 

tweet_islam_sentiment <- tweetfile_clean_islam %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n))


  ggplot(data = tweet_islam_sentiment,
    mapping = aes(x = word, y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scale = "free_y")+
  labs(title = "Sentiment In Tweets Including the Word 'Islam'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = " ",
       y = "Contribution to Sentiment") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) +
  scale_fill_manual(values = c("brown2", "olivedrab3")) 
```

```{r, sentiment analysis arab and south asian}
# Used bing analysis - which counts positive and negative words. Trump is coded
# as positive. 

tweet_arab_sa_sentiment <- tweetfile_clean_arab_sa %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n))

  ggplot(data = tweet_arab_sa_sentiment,
    mapping = aes(x = word, y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scale = "free_y")+
  labs(title = "Sentiment In Tweets Including the Words 'Arab' and '
       South Asian'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = " ",
       y = "Contribution to Sentiment") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) +
  scale_fill_manual(values = c("brown2", "olivedrab3")) 
```

```{r, sentiment analysis anti-dem}
# Used bing analysis - which counts positive and negative words. Trump is 
# coded as positive. 

tweet_antidem_sentiment <- tweetfile_clean_antidem %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n))

  ggplot(data = tweet_antidem_sentiment, 
         mapping = aes(x = word, y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scale = "free_y")+
  labs(title = "Sentiment In Tweets Including the Words 'Anti-Democratic'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = " ",
       y = "Contribution to Sentiment") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) +
  scale_fill_manual(values = c("brown2", "olivedrab3")) 

```

```{r, sentiment analysis aggregate}
# Used bing analysis - which counts positive and negative words. Trump is coded
# as positive. 

tweet_aggregate_sentiment <- tweetfile_clean %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n))

  ggplot(data = tweet_aggregate_sentiment, 
         mapping = aes(x = word, y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scale = "free_y")+
  labs(title = "Sentiment In Tweets Including the Words 'Muslim, 'Islam', 
       'Arab', 'South Asian', and 'Anti-Democratic'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = " ",
       y = "Contribution to Sentiment") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) +
  scale_fill_manual(values = c("brown2", "olivedrab3")) 


```

```{r, sentiment analysis aggregate ethnic}
# Used bing analysis - which counts positive and negative words. Trump is 
# coded as positive. 

tweet_ethnic_sentiment <- tweetfile_clean_ethnic %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  group_by(sentiment) %>%
  top_n(20) %>%
  ungroup() %>%
  mutate(word = reorder(word, n))
  
# making data set separate for later csv download purposes
  
  ggplot(data = tweet_ethnic_sentiment,
         mapping = aes(x = word, y = n, fill = sentiment)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~sentiment, scale = "free_y") +
  labs(title = "Sentiment In Tweets Including the Words 'Muslim, 'Islam',
       'Arab', and 'South Asian'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = " ",
       y = "Contribution to Sentiment") +
  coord_flip() +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) +
  scale_fill_manual(values = c("brown2", "olivedrab3")) 


```

```{r, sentiment numerical}

# Afinn creates a a numerical spectrum of values for sentiment. 0 is neutral. 
# Positive values are postive sentiments.
# Negative values are negative sentiments. 

# Numerical spectrum with tweets including the word Muslim
 
muslim_numerical <- tweetfile_clean_muslim %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  inner_join(get_sentiments("afinn")) 

  ggplot(data = muslim_numerical, 
         mapping = aes(x = value)) +
  geom_histogram(bins = 30, fill = "lightskyblue") +
  ylim(0, 500) +
  labs(title = "Numerical Scale of Sentiment in Tweets Including the 
       Word 'Muslim'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Score",
       y = "Count") +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) 

# Numerical spectrum with tweets including the word Islam

islam_numerical <- tweetfile_clean_islam %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  inner_join(get_sentiments("afinn"))

  ggplot(data = islam_numerical, 
         mapping = aes(x = value)) +
  geom_histogram(bins = 30, fill = "lightskyblue") +
  ylim(0, 500) +
  labs(title = "Numerical Scale of Sentiment in Tweets Including the Word 'Islam'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Score",
       y = "Count") +
  theme_bw() +
  theme(text = element_text(family = "Palatino"))  

# Numerical spectrum with tweets including the words Arab and South Asian

arabsa_numerical <- tweetfile_clean_arab_sa %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  inner_join(get_sentiments("afinn"))

  ggplot(data = arabsa_numerical, mapping = aes(x = value)) +
  geom_histogram(bins = 30, fill = "lightskyblue") +
  ylim(0, 500) +
  labs(title = "Numerical Scale of Sentiment in Tweets Including the Words 'Arab' and 'South Asian'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Score",
       y = "Count") +
  theme_bw() +
  theme(text = element_text(family = "Palatino"))  

# Numerical spectrum with tweets including the word Anti-Democratic

antidem_numerical <- tweetfile_clean_antidem %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  inner_join(get_sentiments("afinn"))

  ggplot(data = antidem_numerical, mapping = aes(x = value)) +
  geom_histogram(bins = 30, fill = "lightskyblue") + 
  ylim(0, 500) +
  labs(title = "Numerical Scale of Sentiment in Tweets Including the Word 'Anti-Democratic'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Score",
       y = "Count") +
  theme_bw() +
  theme(text = element_text(family = "Palatino"))  

# Numerical spectrum with tweets including the words Muslim, Islam, Arab, 
# and South Asian

ethnic_numerical <- tweetfile_clean_ethnic %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  inner_join(get_sentiments("afinn"))

  ggplot(data = ethnic_numerical, mapping = aes(x = value)) +
  geom_histogram(bins = 30, fill = "lightskyblue") +
  ylim(0, 500) +
  labs(title = "Numerical Scale of Sentiment in Tweets Including the Words 'Muslim', 'Islam', 'Arab, and 'South Asian'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Score",
       y = "Count") +
  theme_bw() +
  theme(text = element_text(family = "Palatino")) 

# Numerical spectrum with tweets including the word Muslim, Islam, Arab, 
#  South Asian, and Anti-Democratic - my aggregate data

aggregate_numerical <- tweetfile_clean %>%
  inner_join(get_sentiments("bing")) %>%
  count(word, sentiment, sort = TRUE) %>%
  ungroup() %>%
  inner_join(get_sentiments("afinn"))

  ggplot(data = aggregate_numerical, mapping = aes(x = value)) +
  geom_histogram(bins = 30, fill = "lightskyblue") +
  ylim(0, 500) +
  labs(title = "Numerical Scale of Sentiment in Tweets Including the Words 'Muslim', 'Islam', 'Arab, 'South Asian', and 'Anti-Democratic'", 
       subtitle = "Tweets gathered Nov. 3 - Nov. 17, 2020",
       caption = "Source: Twitter", 
       x = "Score",
       y = "Count") +
  theme_bw() +
  theme(text = element_text(family = "Palatino"))  

```
```{r}

# LANGUAGE! Average sentiment of words in tweets including the word muslim

# Muslim tweet word sentiment predictor
muslim_sentiment_predict <- muslim_numerical %>%
  mutate(weighted = n*value)

# calculates number of tweets and multiplying by score gives weighted mean
# weighted needed because some words pop up more often than others

sum(muslim_sentiment_predict$weighted)/sum(muslim_sentiment_predict$n)

# tells us mean sentiment

muslim_sentiment_predictvector <- rep(c(muslim_sentiment_predict$value), each = c(muslim_sentiment_predict$n))

muslim_straps <- muslim_sentiment_predictvector %>%
  as_tibble() %>%
  bootstraps(times = 100) %>%
  mutate(boot = map(splits, ~ analysis(.))) %>%
  mutate(values = map(boot, ~ pull(., value))) %>% 
  mutate(value_mean = map_dbl(values, ~ mean(.)))

muslimci <- muslim_straps$value_mean

# Islam tweet word sentiment predictor
islam_sentiment_predict <- islam_numerical %>%
  mutate(weighted = n*value)

sum(islam_sentiment_predict$weighted)/sum(islam_sentiment_predict$n)

islam_sentiment_predictvector <- rep(c(islam_sentiment_predict$value), each = c(islam_sentiment_predict$n))

islam_straps <- islam_sentiment_predictvector %>%
  as_tibble() %>%
  bootstraps(times = 100) %>%
  mutate(boot = map(splits, ~ analysis(.))) %>%
  mutate(values = map(boot, ~ pull(., value))) %>% 
  mutate(value_mean = map_dbl(values, ~ mean(.)))

islamci <- islam_straps$value_mean

# Arab and South Asian tweet word sentiment predictor
arab_sa_sentiment_predict <- arabsa_numerical %>%
  mutate(weighted = n*value)

sum(arab_sa_sentiment_predict$weighted)/sum(arab_sa_sentiment_predict$n)

arab_sa_sentiment_predictvector <- rep(c(arab_sa_sentiment_predict$value), each = c(arab_sa_sentiment_predict$n))

arab_sa_straps <- arab_sa_sentiment_predictvector %>%
  as_tibble() %>%
  bootstraps(times = 100) %>%
  mutate(boot = map(splits, ~ analysis(.))) %>%
  mutate(values = map(boot, ~ pull(., value))) %>% 
  mutate(value_mean = map_dbl(values, ~ mean(.)))

arab_saci <- arab_sa_straps$value_mean

# Anti-Democratic tweet word sentiment predictor
antidem_sentiment_predict <- antidem_numerical %>%
  mutate(weighted = n*value)

sum(antidem_sentiment_predict$weighted)/sum(antidem_sentiment_predict$n)

antidem_sentiment_predictvector <- rep(c(antidem_sentiment_predict$value), each = c(antidem_sentiment_predict$n))

antidem_straps <- antidem_sentiment_predictvector %>%
  as_tibble() %>%
  bootstraps(times = 100) %>%
  mutate(boot = map(splits, ~ analysis(.))) %>%
  mutate(values = map(boot, ~ pull(., value))) %>% 
  mutate(value_mean = map_dbl(values, ~ mean(.)))

antidemci <- antidem_straps$value_mean

# Aggregate Ethnic tweet word sentiment predictor
ethnic_sentiment_predict <- ethnic_numerical %>%
  mutate(weighted = n*value)

sum(ethnic_sentiment_predict$weighted)/sum(ethnic_sentiment_predict$n)

ethnic_sentiment_predictvector <- rep(c(ethnic_sentiment_predict$value),
                                      each = c(ethnic_sentiment_predict$n))

ethnic_straps <- ethnic_sentiment_predictvector %>%
  as_tibble() %>%
  bootstraps(times = 100) %>%
  mutate(boot = map(splits, ~ analysis(.))) %>%
  mutate(values = map(boot, ~ pull(., value))) %>% 
  mutate(value_mean = map_dbl(values, ~ mean(.)))

ethnicci <- ethnic_straps$value_mean

# Aggregate tweet word sentiment predictor
aggregate_sentiment_predict <- aggregate_numerical %>%
  mutate(weighted = n*value)

sum(aggregate_sentiment_predict$weighted)/sum(aggregate_sentiment_predict$n)

aggregate_sentiment_predictvector <- rep(c(aggregate_sentiment_predict$value),
                                      each = c(aggregate_sentiment_predict$n))

aggregate_straps <- aggregate_sentiment_predictvector %>%
  as_tibble() %>%
  bootstraps(times = 100) %>%
  mutate(boot = map(splits, ~ analysis(.))) %>%
  mutate(values = map(boot, ~ pull(., value))) %>% 
  mutate(value_mean = map_dbl(values, ~ mean(.)))

aggregateci <- aggregate_straps$value_mean

#manual tibble creation for confidence interval quantiles for c 95
results_tibble <- tibble(tweet_type = c("Muslim", 
                                        "Islam",
                                        "Arab and South Asian",
                                        "Anti-Democratic",
                                        "Aggregate of ethno-religious terms",
                                        "Aggregate of all terms"),
                         mean = c(mean(muslimci),
                                  mean(islamci),
                                  mean(arab_saci),
                                  mean(antidemci),
                                  mean(ethnicci),
                                  mean(aggregateci)),
                         CI_25 = c(quantile(muslimci, 0.025),
                                   quantile(islamci, 0.025),
                                   quantile(arab_saci, 0.025),
                                   quantile(antidemci, 0.025),
                                   quantile(ethnicci, 0.025),
                                   quantile(aggregateci, 0.025)),
                         CI_97.5 = c(quantile(muslimci, 0.975),
                                   quantile(islamci, 0.975),
                                   quantile(arab_saci, 0.975),
                                   quantile(antidemci, 0.975),
                                   quantile(ethnicci, 0.975),
                                   quantile(aggregateci, 0.975))) 
results_tibble
# make it for all and join


# library(gtsummary)
# library(gt)
# 
# output$predictTable <- render_gt(
#         pred_table[rep(row.names(pred_table), pred_table$n), 1:3][, c(1, 3)] %>%
#             rename(Type = type) %>%
#             tbl_summary(by = year )%>% 
#             as_gt()
#     )
# 
# 
# gt_output("predictTable"))

render_gt(
        pred_table[rep(row.names(pred_table), pred_table$n), 1:3][, c(1, 3)] %>%
            as_gt()
    )

results_tibble[rep(row.names(results_tibble), results_tibble$n), 1:3][, c(1, 3)] %>%
            rename(Type = type) %>%
            tbl_summary(by = year )%>%
            as_gt()

results_tibble 

results_tibble

# tbl_regression(intercept = TRUE, estimate_fun = function(x) style_sigfig(x, digits = 5))
```



```{r, write csv for data imported to shiny}

write_csv(tweetfile_clean, "tweetfile_clean.csv")
write_csv(tweetfile_clean_muslim, "tweetfile_clean_muslim.csv")
write_csv(tweetfile_clean_islam, "tweetfile_clean_islam.csv")
write_csv(tweetfile_clean_arab_sa, "tweetfile_clean_arab_sa.csv")
write_csv(tweetfile_clean_antidem, "tweetfile_clean_antidem.csv")
write_csv(tweetfile_clean_ethnic, "tweetfile_clean_ethnic.csv")

write_csv(tweet_muslim_sentiment, "tweetfile_muslim_sentiment.csv")
write_csv(tweet_islam_sentiment, "tweetfile_islam_sentiment.csv")
write_csv(tweet_arab_sa_sentiment, "tweetfile_arab_sa_sentiment.csv")
write_csv(tweet_antidem_sentiment, "tweetfile_antidem_sentiment.csv")
write_csv(tweet_ethnic_sentiment, "tweetfile_ethnic_sentiment.csv")
write_csv(tweet_aggregate_sentiment, "tweetfile_aggregate_sentiment.csv")

write_csv(muslimwords, "muslimwords.csv")
write_csv(islamwords, "islamwords.csv")
write_csv(arabsawords, "arabsawords.csv")
write_csv(antidemwords, "antidemwords.csv")
write_csv(ethnicwords, "ethnicwords.csv")
write_csv(totalwords, "totalwords.csv")

write_csv(muslim_numerical, "muslim_numerical.csv")
write_csv(islam_numerical, "islam_numerical.csv")
write_csv(arabsa_numerical, "arabsa_numerical.csv")
write_csv(antidem_numerical, "antidem_numerical.csv")
write_csv(ethnic_numerical, "ethnic_numerical.csv")
write_csv(aggregate_numerical, "aggregate_numerical.csv")

write_csv(results_tibble, "ci.csv")
```

